# 百度网盘AI大赛-文档检测优化赛第4名方案

## 比赛描述
生活中人们使用手机进行文档扫描逐渐成为一件普遍的事情，为了提高人们的使用体验，我们期望通过算法技术去除杂乱的拍摄背景并精准框取文档边缘，选手需要通过深度学习技术训练模型，对给定的真实场景下采集得到的带有拍摄背景的文件图片进行边缘智能识别，并最终输出处理后的扫描结果图片。

本次比赛希望选手结合当下前沿的图像处理技术与计算机视觉技术，提升模型的训练性能和泛化能力，在保证效果精准的同时，注意模型在实际应用中的性能问题，做到尽可能的小而快。

在本次比赛最新发布的数据集中，大部分图像数据均是通过真实场景拍摄采集的，小部分是通过网络公开数据收集的。该任务的输入为文档类型的图像，期望输出文档图像四个角的坐标点，由于不是所有的文档图像都是规则的四边形，因此本次比赛提供的训练数据中包括四个部分：文档图像、文档边缘坐标点、预生成的边缘heatmap图、预生成的文档区域分割图，其中，图像四个角的坐标点可通过文档边缘坐标点来生成；发布的数据集GT形式较多，是为了不限制大家完成该任务的思路。另外，为达到更好的算法效果，本次比赛不限制大家使用额外的训练数据来优化模型。

本次比赛最新发布的数据集共包含训练集、A榜测试集、B榜测试集三个部分，其中，训练集共2797个样本，A榜测试集共597个样本，B榜测试集共606个样本；
images 为文档图像数据，edges 为预生成的边缘heatmap图，segments 为预生成的文档区域分割图，根据图片名称一一对应；
data_info.txt 文件中的每一行对应一个图像样本，其数据格式如下： 图片名称,x1,y1,x2,y2,x3,y3,…,xn,yn

## 解决方案
一开始采用resnet152加上一个全连接层直接预测四个点的坐标，但是这么做的效果不理想，采用swin base做backbone做多达到95的miou。所以后面采用分割的方式来解决该问题，网络结构采用的是swin base的backbone和fpn解码器，训练30epoch就可以达到97.2的miou，loss采用的是dice loss和Lovasz loss的加权，这是针对miou的loss，但是结果分数是要根据分割图先转换成四个坐标，然后填充由该四个坐标组成的四边形，用四边形mask与GT计算iou，所以分割边界对于结果十分重要，后续采用DetailAggregateLoss，但是算力问题，训练轮次过少，并没有提升。对于这个问题，我觉得分割的结果都很好，但是四个坐标点十分重要，需要找出分割图的最小外接四边形，所以也试过在分割图后级联一个swin base + 全连接层输出四个坐标，相当于直接对分割图回归，没有引入原图信息，但是效果不理想，直接提交级联的第一个网络的分割结果，miou还是能到97，但是提交坐标结果，结果只有95。

## 使用方式
swin预训练模型以及最后的模型权重在百度网盘中获取，链接如下：
链接：https://pan.baidu.com/s/13ryo2dt_XYgscdQ_3m2GOQ 
提取码：p36n
